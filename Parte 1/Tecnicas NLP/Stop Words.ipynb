{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Stop Words.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbfeTQY5sCtj2hdnOOBV9e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Stop Words"],"metadata":{"id":"30REdXmXDPXA"}},{"cell_type":"markdown","source":["Existen multiples librerias en python que pueden facilitar la tarea de extraer las stop words de un texto, veremos algunos ejemplos"],"metadata":{"id":"3SjrUX9FDdPi"}},{"cell_type":"code","source":["texto_por_defecto = 'me gusta mucho comer pasta'"],"metadata":{"id":"24JwvD5_JAb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Usando NLTK"],"metadata":{"id":"ASRWt5A7Dosh"}},{"cell_type":"code","source":["import nltk # importamos NLTK\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","from nltk.corpus import stopwords # importamos stopwords del paquete nltk.corpus para obtener las Stop Words\n","\n","from nltk.tokenize import word_tokenize # Importamos word_tokenize del paquete nltk.tokenize, para separar nuestro texto en palabras\n","\n","stop_word_spanish = stopwords.words('spanish') # Obtenemos las stop words para un determinado idioma, en este caso español\n","print('Stop words en español',stop_word_spanish) # Mostramos las Stop words en el idioma seleccionado\n","\n","texto_por_defecto  = \"me gusta mucho la pasta\"\n","\n","texto_ejemplo = input(\"Por favor introduce un texto o pulsa intro para usar el texto por defecto\\n\") # Solicitamos a el usuario un texto, a partir del cual extraeremos las Stop Words\n","texto_ejemplo = texto_ejemplo if texto_ejemplo is not \"\" else texto_por_defecto\n","tokens_texto = word_tokenize(texto_ejemplo) # Dividimos el texto en tokens o palabras\n","\n","# para cada palabra, comprobaremos si esta en la lista de stop words, y de no ser asi la añadiremos a una nueva lista que contendra la frase anterior, sin stop words\n","tokens_sin_sw = [word for word in tokens_texto if not word in stop_word_spanish] \n","\n","print('Texto original:',tokens_texto) # Mostramos los tokens del texto original\n","print('Texto sin stop words:',tokens_sin_sw) # Mostramos los tokens del texto sin stop words\n","print('Stop Words eliminadas:',list(set(tokens_texto).difference(set(tokens_sin_sw)))) # Mostramos las stop words eliminadas del texto"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7iZwenIgDvev","executionInfo":{"status":"ok","timestamp":1649606319326,"user_tz":-120,"elapsed":3041,"user":{"displayName":"Daniel Ruiz Santamaría","userId":"00829749213257681441"}},"outputId":"b3991f24-1379-401e-c8f6-9771fa833349"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","Stop words en español ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n","Por favor introduce un texto o pulsa intro para usar el texto por defecto\n","\n","Texto original: ['me', 'gusta', 'mucho', 'la', 'pasta']\n","Texto sin stop words: ['gusta', 'pasta']\n","Stop Words eliminadas: ['la', 'mucho', 'me']\n"]}]},{"cell_type":"markdown","source":["## Usando SPACY"],"metadata":{"id":"KayY9jd8HYYf"}},{"cell_type":"code","source":["!python -m spacy download es\n","import spacy\n","from nltk.tokenize import word_tokenize\n","# cargamos el languaje español de spaCy\n","en_model = spacy.load('es')\n","\n","stop_word_spanish = en_model.Defaults.stop_words # Obtenemos la lista de stop words\n","print('Stop words en español',list(stop_word_spanish)) # Mostramos las Stop words en el idioma seleccionado\n","\n","texto_ejemplo = input(\"Por favor introduce un texto o pulsa intro para usar el texto por defecto\\n\") # Solicitamos a el usuario un texto, a partir del cual extraeremos las Stop Words\n","texto_ejemplo = texto_ejemplo if texto_ejemplo is not \"\" else texto_por_defecto # Usamos el texto por defecto si el usuario no introdujo nada\n","tokens_texto = word_tokenize(texto_ejemplo) # Dividimos el texto en tokens o palabras\n","# para cada palabra, comprobaremos si esta en la lista de stop words, y de no ser asi la añadiremos a una nueva lista que contendra la frase anterior, sin stop words\n","tokens_sin_sw = [word for word in tokens_texto if not word in stop_word_spanish] \n","\n","print('Texto original:',tokens_texto) # Mostramos los tokens del texto original\n","print('Texto sin stop words:',tokens_sin_sw) # Mostramos los tokens del texto sin stop words\n","print('Stop Words eliminadas:',list(set(tokens_texto).difference(set(tokens_sin_sw)))) # Mostramos las stop words eliminadas del texto"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2r0_A4ueHg7n","executionInfo":{"status":"ok","timestamp":1649606350248,"user_tz":-120,"elapsed":19583,"user":{"displayName":"Daniel Ruiz Santamaría","userId":"00829749213257681441"}},"outputId":"acaf0b63-5853-40e9-8289-472fd1e71c75"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting es_core_news_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.2.5/es_core_news_sm-2.2.5.tar.gz (16.2 MB)\n","\u001b[K     |████████████████████████████████| 16.2 MB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (4.63.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.21.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (0.9.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_sm==2.2.5) (2.10)\n","Building wheels for collected packages: es-core-news-sm\n","  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.2.5-py3-none-any.whl size=16172933 sha256=d7073ad70621ee70fd215676f52c9fa7acfdf9a991c78d02784e7fdc7415f0da\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-zwrdawem/wheels/21/8d/a9/6c1a2809c55dd22cd9644ae503a52ba6206b04aa57ba83a3d8\n","Successfully built es-core-news-sm\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('es_core_news_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/es_core_news_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/es\n","You can now load the model via spacy.load('es')\n","Stop words en español ['usamos', 'tercera', 'ultimo', 'antes', 'lo', 'poco', 'así', 'aún', 'aquellos', 'da', 'acuerdo', 'siendo', 'eso', 'próximos', 'sois', 'segun', 'haces', 'todavía', 'conseguimos', 'tienen', 'tener', 'desde', 'tan', 'tu', 'aquella', 'habían', 'saber', 'antano', 'ellas', 'estas', 'consideró', 'ese', 'través', 'creo', 'peor', 'usar', 'eramos', 'cuanto', 'fueron', 'tenga', 'sea', 'esa', 'parece', 'trabajais', 'cuántas', 'delante', 'qeu', 'dio', 'aseguró', 'lado', 'salvo', 'nunca', 'ciertas', 'suyas', 'hoy', 'sus', 'detras', 'propia', 'siete', 'misma', 'os', 'consigues', 'algunos', 'estais', 'éstos', 'mejor', 'segunda', 'quizas', 'solas', 'sabes', 'unos', 'esos', 'de', 'gueno', 'ambos', 'propias', 'ya', 'ningunos', 'intenta', 'aquéllas', 'todavia', 'mayor', 'sola', 'ha', 'trabajo', 'mios', 'pocos', 'última', 'intentamos', 'próximo', 'estuvo', 'vuestros', 'cuando', 'nadie', 'podrían', 'tuyas', 'diferentes', 'partir', 'mía', 'tenido', 'fuera', 'ti', 'deben', 'nosotros', 'paìs', 'me', 'vuestras', 'mío', 'sabemos', 'cuántos', 'señaló', 'sean', 'tengo', 'mientras', 'sé', 'dan', 'decir', 'donde', 'verdadera', 'hay', 'intentas', 'la', 'quizás', 'deprisa', 'nuestra', 'dice', 'cuanta', 'ustedes', 'para', 'aqui', 'hicieron', 'muchas', 'estamos', 'pudo', 'ésta', 'quienes', 'somos', 'quiza', 'ella', 'dado', 'mas', 'puedo', 'estan', 'seis', 'lugar', 'trabajas', 'sigue', 'habrá', 'otros', 'vaya', 'anterior', 'ver', 'cuenta', 'quién', 'cuantas', 'informó', 'ésa', 'le', 'éste', 'total', 'encuentra', 'se', 'tambien', 'primer', 'mismos', 'mio', 'tampoco', 'quizá', 'diferente', 'haceis', 'horas', 'estado', 'mismas', 'sólo', 'embargo', 'hablan', 'igual', 'porque', 'ante', 'usais', 'podrá', 'junto', 'excepto', 'alli', 'detrás', 'también', 'usas', 'claro', 'cada', 'valor', 'modo', 'parte', 'manera', 'segundo', 'tendrán', 'aquellas', 'muy', 'pero', 'sino', 'otra', 'del', 'el', 'ningún', 'podría', 'había', 'suya', 'luego', 'cerca', 'dijeron', 'cuánta', 'cuándo', 'toda', 'más', 'cual', 'uso', 'mí', 'cierto', 'sabe', 'ir', 'según', 'vuestra', 'considera', 'queremos', 'va', 'será', 'tras', 'ahi', 'mencionó', 'van', 'mias', 'aproximadamente', 'podria', 'ex', 'hace', 'buenos', 'hacen', 'son', 'general', 'llegó', 'estoy', 'aquél', 'conocer', 'tres', 'habia', 'informo', 'buenas', 'dicho', 'ademas', 'entre', 'respecto', 'mismo', 'pasado', 'solamente', 'tenemos', 'propio', 'manifestó', 'menos', 'adelante', 'hizo', 'fue', 'quien', 'esta', 'fuimos', 'afirmó', 'ninguno', 'otro', 'proximo', 'ocho', 'su', 'enfrente', 'podrias', 'éstas', 'mal', 'primeros', 'nosotras', 'sido', 'hacerlo', 'alrededor', 'ciertos', 'largo', 'trabajamos', 'consigue', 'algunas', 'alguno', 'hecho', 'eres', 'nada', 'últimas', 'bajo', 'solos', 'míos', 'soy', 'en', 'ayer', 'intentar', 'este', 'sabeis', 'aquel', 'arriba', 'poca', 'último', 'hacia', 'nuevo', 'que', 'teneis', 'habla', 'comentó', 'existen', 'vosotros', 'algún', 'quiere', 'tendrá', 'dia', 'mucho', 'dijo', 'usa', 'encima', 'varios', 'pueda', 'tiempo', 'tenía', 'aun', 'cómo', 'esto', 'hacemos', 'estados', 'estará', 'tiene', 'tuvo', 'estos', 'trabajan', 'siempre', 'asi', 'hasta', 'debe', 'verdadero', 'muchos', 'eras', 'actualmente', 'suyo', 'mediante', 'ése', 'podriamos', 'todo', 'explicó', 'varias', 'primero', 'sería', 'ampleamos', 'intento', 'consigo', 'las', 'despacio', 'raras', 'siguiente', 'cierta', 'pues', 'debajo', 'antaño', 'trabajar', 'ello', 'buen', 'conseguir', 'dentro', 'qué', 'bien', 'demás', 'sobre', 'hemos', 'dejó', 'días', 'entonces', 'haciendo', 'podemos', 'esas', 'cualquier', 'dieron', 'enseguida', 'eran', 'soyos', 'tus', 'aquello', 'cuál', 'serán', 'temprano', 'cuáles', 'yo', 'primera', 'tuya', 'una', 'vamos', 'contigo', 'con', 'mías', 'lejos', 'quiénes', 'cosas', 'adrede', 'debido', 'él', 'tuyos', 'trata', 'vais', 'emplean', 'buena', 'fui', 'veces', 'te', 'mi', 'no', 'podrán', 'apenas', 'pais', 'mia', 'como', 'despues', 'estar', 'solo', 'sí', 'consiguen', 'todas', 'allí', 'agregó', 'estaba', 'sera', 'está', 'al', 'tuyo', 'podriais', 'aunque', 'conmigo', 'alguna', 'ellos', 'nos', 'empleas', 'poner', 'tú', 'pesar', 'lleva', 'quedó', 'aquéllos', 'han', 'realizado', 'últimos', 'aquélla', 'nueva', 'realizó', 'ninguna', 'pasada', 'supuesto', 'cinco', 'unas', 'ejemplo', 'pueden', 'nuestras', 'un', 'es', 'verdad', 'mucha', 'era', 'medio', 'si', 'fin', 'empleais', 'tanto', 'voy', 'sin', 'vuestro', 'además', 'usted', 'intentan', 'añadió', 'incluso', 'saben', 'indicó', 'podeis', 'día', 'hago', 'tarde', 'dónde', 'dicen', 'casi', 'cuatro', 'aquí', 'nuevas', 'final', 'momento', 'principalmente', 'contra', 'dos', 'uno', 'cuánto', 'emplear', 'atras', 'expresó', 'mis', 'bueno', 'pronto', 'demasiado', 'repente', 'les', 'ni', 'bastante', 'poder', 'grandes', 'cuales', 'llevar', 'existe', 'otras', 'todos', 'tal', 'haber', 'breve', 'trabaja', 'nuestro', 'nuestros', 'propios', 'después', 'estaban', 'hacer', 'están', 'arribaabajo', 'usan', 'por', 'intentais', 'gran', 'nuevos', 'puede', 'ahí', 'ser', 'ahora', 'vez', 'he', 'los', 'ningunas', 'ésas', 'haya', 'algo', 'hubo', 'posible', 'vosotras', 'realizar', 'dias', 'menudo', 'empleo', 'ésos', 'pocas', 'podrian', 'dar', 'durante', 'cuantos']\n","Por favor introduce un texto o pulsa intro para usar el texto por defecto\n","\n","Texto original: ['me', 'gusta', 'mucho', 'la', 'pasta']\n","Texto sin stop words: ['gusta', 'pasta']\n","Stop Words eliminadas: ['la', 'mucho', 'me']\n"]}]},{"cell_type":"markdown","source":["# Usando Gensim"],"metadata":{"id":"MSvYdIbfOYxn"}},{"cell_type":"code","source":["from gensim.parsing.preprocessing import remove_stopwords\n","from gensim.parsing.preprocessing import STOPWORDS\n","\n","sample_text = \"Oh man, this is pretty cool. We will do more such things.\"\n","sample_text_NSW = remove_stopwords(sample_text)\n","print(STOPWORDS)\n","print(word_tokenize(sample_text))\n","print(word_tokenize(sample_text_NSW))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODCQgzjfOnsQ","executionInfo":{"status":"ok","timestamp":1649606363605,"user_tz":-120,"elapsed":995,"user":{"displayName":"Daniel Ruiz Santamaría","userId":"00829749213257681441"}},"outputId":"fda90365-2510-4eb0-9e8d-e3431d61f2f0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["frozenset({'itself', 'up', 'done', 'describe', 'or', 'them', 'anyone', 'again', 'whole', 'thereupon', 'there', 'in', 'yourself', 'otherwise', 'cry', 'however', 'nothing', 'besides', 'hereafter', 'might', 'upon', 'seeming', 'too', 'none', 'mostly', 'eg', 'still', 'why', 'into', 'under', 'sometime', 'their', 'thence', 'would', 'because', 'de', 'within', 'among', 'hundred', 'us', 'after', 'latterly', 'and', 'it', 'nevertheless', 'don', 'around', 'herself', 'what', 'give', 'several', 'find', 'few', 'see', 'doing', 'twelve', 'whenever', 'wherein', 'used', 'therein', 'myself', 'say', 'move', 'me', 'must', 'about', 'empty', 'though', 'nowhere', 'they', 'less', 'ever', 'twenty', 'between', 'him', 'do', 'hers', 'beforehand', 'sometimes', 'ourselves', 'i', 'etc', 'front', 'anywhere', 'keep', 'almost', 'neither', 'for', 'will', 'every', 'quite', 'fire', 'could', 'onto', 'just', 'towards', 'your', 'elsewhere', 'yet', 'make', 'even', 'put', 'this', 'computer', 'at', 'since', 'its', 'side', 'other', 'someone', 'any', 'is', 'ie', 'thick', 'where', 'her', 'has', 'show', 'but', 'often', 'enough', 'made', 'never', 'becomes', 'then', 'part', 'am', 'amoungst', 'anyway', 'six', 'before', 'much', 'therefore', 'rather', 'some', 'each', 'than', 'already', 'of', 'third', 'ltd', 'further', 'toward', 'whither', 'very', 'can', 'mine', 'others', 'well', 'name', 'top', 'these', 'if', 'who', 'mill', 'whereby', 'against', 're', 'everything', 'via', 'should', 'an', 'system', 'became', 'all', 'across', 'without', 'to', 'nobody', 'indeed', 'himself', 'the', 'hence', 'being', 'eight', 'sixty', 'seemed', 'everyone', 'whoever', 'formerly', 'moreover', 'km', 'first', 'using', 'except', 'also', 'wherever', 'have', 'thin', 'down', 'be', 'anyhow', 'herein', 'along', 'five', 'back', 'here', 'beyond', 'please', 'fill', 'although', 'many', 'fify', 'nor', 'whereas', 'co', 'something', 'as', 'ours', 'are', 'thereafter', 'cannot', 'more', 'really', 'didn', 'whence', 'through', 'that', 'she', 'whether', 'three', 'kg', 'been', 'during', 'bill', 'get', 'not', 'con', 'by', 'behind', 'whereupon', 'were', 'namely', 'themselves', 'may', 'those', 'sincere', 'a', 'two', 'now', 'such', 'no', 'somewhere', 'throughout', 'on', 'go', 'together', 'bottom', 'ten', 'thru', 'nine', 'you', 'only', 'couldnt', 'until', 'whose', 'did', 'amount', 'hereupon', 'regarding', 'was', 'everywhere', 'does', 'beside', 'amongst', 'next', 'serious', 'take', 'noone', 'found', 'seem', 'least', 'hasnt', 'due', 'our', 'another', 'un', 'below', 'four', 'most', 'perhaps', 'alone', 'seems', 'from', 'latter', 'which', 'per', 'hereby', 'how', 'else', 'always', 'becoming', 'eleven', 'cant', 'yourselves', 'own', 'his', 'call', 'become', 'unless', 'full', 'with', 'fifteen', 'various', 'both', 'above', 'whereafter', 'same', 'out', 'once', 'last', 'former', 'so', 'thereby', 'anything', 'yours', 'had', 'while', 'doesn', 'we', 'whom', 'somehow', 'whatever', 'one', 'he', 'thus', 'forty', 'interest', 'meanwhile', 'when', 'afterwards', 'my', 'inc', 'detail', 'off', 'over', 'either'})\n","['Oh', 'man', ',', 'this', 'is', 'pretty', 'cool', '.', 'We', 'will', 'do', 'more', 'such', 'things', '.']\n","['Oh', 'man', ',', 'pretty', 'cool', '.', 'We', 'things', '.']\n"]}]}]}